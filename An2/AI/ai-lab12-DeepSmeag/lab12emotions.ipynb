{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy pandas etc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load twitter data\n",
    "data = pd.read_csv(\"sent.csv\", header=None, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data columns:\n",
    "# 0 - sentiment (0 = negative, 2 = neutral, 4 = positive)\n",
    "# 1 - id of tweet\n",
    "# 2 - date of tweet\n",
    "# 3 - query\n",
    "# 4 - user\n",
    "# 5 - text\n",
    "# change column names\n",
    "data.columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_820/155909423.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processedData['sentiment'] = processedData['sentiment'].replace({4: 1})  # Convert positive sentiment to 1\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "processedData = data[['sentiment', 'text']]\n",
    "processedData['sentiment'] = processedData['sentiment'].replace({4: 1})  # Convert positive sentiment to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_820/520913739.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processedData['sentiment'] = processedData['sentiment'].replace({0: -1})  # Convert negative sentiment to -1\n",
      "/tmp/ipykernel_820/520913739.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processedData['sentiment'] = processedData['sentiment'].replace({2: 0})  # Convert neutral sentiment to 0\n"
     ]
    }
   ],
   "source": [
    "# move sentiment to -1,0,1\n",
    "processedData['sentiment'] = processedData['sentiment'].replace({0: -1})  # Convert negative sentiment to -1\n",
    "processedData['sentiment'] = processedData['sentiment'].replace({2: 0})  # Convert neutral sentiment to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['text'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text sequences to numerical sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
    "\n",
    "# Pad the sequences to have the same length\n",
    "max_sequence_length = 100  # Set the desired sequence length\n",
    "train_data_padded = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "test_data_padded = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert the target labels to categorical\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_data['sentiment'])\n",
    "test_labels = label_encoder.transform(test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM model\n",
    "embedding_dim = 100  # Set the embedding dimension\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 139ms/step - loss: 1.7819 - accuracy: 0.3291 - val_loss: -1.0979 - val_accuracy: 0.3400\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.1808 - accuracy: 0.2638 - val_loss: -0.9770 - val_accuracy: 0.3400\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.1150 - accuracy: 0.2638 - val_loss: -0.7888 - val_accuracy: 0.3400\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 121ms/step - loss: -0.0087 - accuracy: 0.2638 - val_loss: -0.6013 - val_accuracy: 0.3400\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: -0.1523 - accuracy: 0.2638 - val_loss: -0.7267 - val_accuracy: 0.3400\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 107ms/step - loss: -0.5991 - accuracy: 0.2739 - val_loss: -1.1272 - val_accuracy: 0.3400\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -2.0318 - accuracy: 0.3769 - val_loss: -1.8215 - val_accuracy: 0.3900\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: -3.6219 - accuracy: 0.4799 - val_loss: -3.1259 - val_accuracy: 0.3600\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: -4.7888 - accuracy: 0.5628 - val_loss: -3.3001 - val_accuracy: 0.3800\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 108ms/step - loss: -5.1419 - accuracy: 0.5955 - val_loss: -3.3265 - val_accuracy: 0.4200\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 105ms/step - loss: -5.2501 - accuracy: 0.6281 - val_loss: -3.3326 - val_accuracy: 0.3800\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 2s 122ms/step - loss: -5.3204 - accuracy: 0.6281 - val_loss: -3.3364 - val_accuracy: 0.4200\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 2s 138ms/step - loss: -5.3391 - accuracy: 0.6382 - val_loss: -3.3140 - val_accuracy: 0.4100\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -5.3541 - accuracy: 0.6256 - val_loss: -3.3153 - val_accuracy: 0.3900\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -5.3849 - accuracy: 0.6357 - val_loss: -3.2723 - val_accuracy: 0.4200\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -5.3952 - accuracy: 0.6382 - val_loss: -3.1602 - val_accuracy: 0.4700\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 1s 107ms/step - loss: -5.3914 - accuracy: 0.6407 - val_loss: -3.3326 - val_accuracy: 0.4000\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: -5.3995 - accuracy: 0.6407 - val_loss: -3.3316 - val_accuracy: 0.4000\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.2199 - val_accuracy: 0.4500\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -5.3994 - accuracy: 0.6407 - val_loss: -3.2690 - val_accuracy: 0.4300\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: -5.4007 - accuracy: 0.6407 - val_loss: -3.2591 - val_accuracy: 0.4400\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 1s 107ms/step - loss: -5.4003 - accuracy: 0.6407 - val_loss: -2.4877 - val_accuracy: 0.4600\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: -5.3999 - accuracy: 0.6407 - val_loss: -2.9391 - val_accuracy: 0.4400\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 1s 104ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.2202 - val_accuracy: 0.4400\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 2s 124ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -2.9458 - val_accuracy: 0.4400\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -2.8925 - val_accuracy: 0.4500\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 1s 107ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -2.8754 - val_accuracy: 0.4500\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: -5.4002 - accuracy: 0.6407 - val_loss: -3.3461 - val_accuracy: 0.4000\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -5.3977 - accuracy: 0.6382 - val_loss: -3.3668 - val_accuracy: 0.4100\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.2682 - val_accuracy: 0.4600\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: -5.4002 - accuracy: 0.6407 - val_loss: -3.3197 - val_accuracy: 0.4400\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 2s 121ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.3733 - val_accuracy: 0.4200\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.3773 - val_accuracy: 0.4200\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 1s 108ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.3788 - val_accuracy: 0.4200\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 1s 104ms/step - loss: -5.4017 - accuracy: 0.6407 - val_loss: -3.3464 - val_accuracy: 0.4200\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 2s 126ms/step - loss: -5.4009 - accuracy: 0.6407 - val_loss: -3.3313 - val_accuracy: 0.4500\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.3770 - val_accuracy: 0.4400\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.3943 - val_accuracy: 0.4400\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.4071 - val_accuracy: 0.4300\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.3988 - val_accuracy: 0.4300\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 1s 105ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.4061 - val_accuracy: 0.4300\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 1s 104ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.4040 - val_accuracy: 0.4300\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -5.4005 - accuracy: 0.6407 - val_loss: -3.0981 - val_accuracy: 0.4700\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.0234 - val_accuracy: 0.4700\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 1s 105ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.0087 - val_accuracy: 0.4800\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 1s 105ms/step - loss: -5.4002 - accuracy: 0.6407 - val_loss: -3.0551 - val_accuracy: 0.4700\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 2s 174ms/step - loss: -5.3971 - accuracy: 0.6407 - val_loss: -3.2676 - val_accuracy: 0.3700\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: -5.3968 - accuracy: 0.6407 - val_loss: -3.3571 - val_accuracy: 0.4300\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 2s 125ms/step - loss: -5.3979 - accuracy: 0.6407 - val_loss: -3.0079 - val_accuracy: 0.4600\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 2s 122ms/step - loss: -5.4019 - accuracy: 0.6407 - val_loss: -3.1687 - val_accuracy: 0.4600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6c1006b940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_data_padded, train_labels, validation_data=(test_data_padded, test_labels), epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 25ms/step - loss: -3.1687 - accuracy: 0.4600\n",
      "Test Loss: -3.1687488555908203\n",
      "Test Accuracy: 0.46000000834465027\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_data_padded, test_labels)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 5 random tweets and their labels from the processedData\n",
    "sample = processedData.sample(5)\n",
    "sample_labels = sample['sentiment'].values.tolist()\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample['text'])\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_sequence_length)\n",
    "toPredict = processedData.sample(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sentiment                                               text\n",
      "161         -1  Recovering from surgery..wishing @julesrenner ...\n",
      "444          0  This is cold.. I was looking at google's chart...\n",
      "165         -1  @kirstiealley my dentist is great but she's ex...\n",
      "475          0  has a date with bobby flay and gut fieri from ...\n",
      "412          0  First dentist appointment [in years] on Wednes...\n",
      "[-1, 0, -1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# print\n",
    "print(sample)\n",
    "print(sample_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmkobs             3\n",
      "MamiYessi          2\n",
      "tradecruz          2\n",
      "SimpleManJess      2\n",
      "souleaterjh        2\n",
      "                  ..\n",
      "sinostream         1\n",
      "drlombardo         1\n",
      "myfoxdc            1\n",
      "BreakingBizNews    1\n",
      "captain_pete       1\n",
      "Name: user, Length: 490, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print all data where user is 'chadfu'\n",
    "# data['user']\n",
    "# print unique\n",
    "# print(data['user'].unique())\n",
    "# print unique users and how many tweets\n",
    "print(data['user'].value_counts())\n",
    "# print(data.loc[data['user'] == 'chadfu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Function to generate a single instance\n",
    "def generate_instance():\n",
    "    length = random.randint(1, 10)  # Random length of the instance\n",
    "    numbers = random.choices([-1, 0, 1], k=length)  # Random numbers (-1, 0, or 1)\n",
    "    majority = np.sign(np.sum(numbers))  # Majority label\n",
    "    return numbers, majority\n",
    "\n",
    "# Generate instances and collect them in a list\n",
    "instances = []\n",
    "for _ in range(100000):\n",
    "    numbers, majority = generate_instance()\n",
    "    instances.append((numbers, majority))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "data = pd.DataFrame(instances, columns=[\"Numbers\", \"Majority\"])\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "data.to_csv(\"synthetic_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify Numbers to be string\n",
    "data['Numbers'] = data['Numbers'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform Majority to dummies\n",
    "data = pd.get_dummies(data, columns=['Majority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numbers</th>\n",
       "      <th>Majority_-1</th>\n",
       "      <th>Majority_0</th>\n",
       "      <th>Majority_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1 -1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1 -1 1 0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 -1 -1 0 -1 -1 0 0 -1 0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 0 -1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>-1 0 1 0 1 1 1 0 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>-1 0 -1 0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>-1 -1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>-1 -1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Numbers  Majority_-1  Majority_0  Majority_1\n",
       "0                         -1 -1            1           0           0\n",
       "1                     -1 -1 1 0            1           0           0\n",
       "2      0 -1 -1 0 -1 -1 0 0 -1 0            1           0           0\n",
       "3                             1            0           0           1\n",
       "4                        1 0 -1            0           1           0\n",
       "...                         ...          ...         ...         ...\n",
       "99995                         0            0           1           0\n",
       "99996        -1 0 1 0 1 1 1 0 1            0           0           1\n",
       "99997                 -1 0 -1 0            1           0           0\n",
       "99998                     -1 -1            1           0           0\n",
       "99999                     -1 -1            1           0           0\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the target labels to categorical\n",
    "train_majority = train_data[['Majority_-1', 'Majority_0', 'Majority_1']].values\n",
    "test_majority = test_data[['Majority_-1', 'Majority_0', 'Majority_1']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Majority'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Majority'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m test_data_padded \u001b[39m=\u001b[39m pad_sequences(test_sequences, maxlen\u001b[39m=\u001b[39mmax_sequence_length)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Convert the majority column to an array\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m train_majority \u001b[39m=\u001b[39m train_data[\u001b[39m\"\u001b[39;49m\u001b[39mMajority\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     23\u001b[0m test_majority \u001b[39m=\u001b[39m test_data[\u001b[39m\"\u001b[39m\u001b[39mMajority\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Majority'"
     ]
    }
   ],
   "source": [
    "# Convert the numbers column to a string\n",
    "data[\"Numbers\"] = data[\"Numbers\"].apply(eval).apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data[\"Numbers\"])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text sequences to numerical sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data[\"Numbers\"])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data[\"Numbers\"])\n",
    "\n",
    "# Pad the sequences to have the same length\n",
    "max_sequence_length = max(len(seq) for seq in train_sequences + test_sequences)\n",
    "train_data_padded = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "test_data_padded = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert the majority column to an array\n",
    "train_majority = train_data[\"Majority\"].values\n",
    "test_majority = test_data[\"Majority\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM model\n",
    "embedding_dim = 64  # Set the embedding dimension\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 22:19:20.403616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-03 22:19:20.404934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-03 22:19:20.406790: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-03 22:19:20.582133: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-03 22:19:20.583705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-03 22:19:20.585039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 22:19:27.479926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-03 22:19:27.482950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-03 22:19:27.486183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-03 22:19:27.690387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-03 22:19:27.693409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-03 22:19:27.695800: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-03 22:19:28.492319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-03 22:19:28.494675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-03 22:19:28.496490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-03 22:19:28.677284: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-03 22:19:28.678701: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-03 22:19:28.680705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2500 [============================>.] - ETA: 0s - loss: 0.5976 - accuracy: 0.4154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 22:20:10.768880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-03 22:20:10.770633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-03 22:20:10.771882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-03 22:20:10.957316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-03 22:20:10.959263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-03 22:20:10.960598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 48s 18ms/step - loss: 0.5976 - accuracy: 0.4154 - val_loss: 0.5525 - val_accuracy: 0.4600\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 0.5188 - accuracy: 0.4793 - val_loss: 0.5469 - val_accuracy: 0.4635\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 0.5133 - accuracy: 0.4781 - val_loss: 0.5111 - val_accuracy: 0.4772\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 0.5130 - accuracy: 0.4778 - val_loss: 0.5107 - val_accuracy: 0.4816\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 0.5123 - accuracy: 0.4806 - val_loss: 0.5103 - val_accuracy: 0.4852\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 0.5119 - accuracy: 0.4814 - val_loss: 0.5103 - val_accuracy: 0.4838\n",
      "Epoch 7/50\n",
      " 682/2500 [=======>......................] - ETA: 31s - loss: 0.5134 - accuracy: 0.4779"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Compile and train the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_data_padded, train_majority, validation_data\u001b[39m=\u001b[39;49m(test_data_padded, test_majority), epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/mnt/e/codinganddev/pythons/aiMaterie/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_data_padded, train_majority, validation_data=(test_data_padded, test_majority), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 5s 8ms/step - loss: 0.5097 - accuracy: 0.4868\n",
      "Test Loss: 0.5096907019615173\n",
      "Test Accuracy: 0.4867500066757202\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_data_padded, test_majority)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "Number: ['1']\n",
      "Real Label: [[0, 0, 1]]\n",
      "Predicted Label: [[4.8005041e-01 3.7434061e-06 5.1994586e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Take 1 random example from the test set, predict it then show real label\n",
    "sample = test_data.sample(1)\n",
    "sample_number = sample[\"Numbers\"].values.tolist()\n",
    "sample_majority = sample[[\"Majority_-1\", \"Majority_0\", \"Majority_1\"]].values.tolist()\n",
    "sample_sequence = tokenizer.texts_to_sequences(sample_number)\n",
    "sample_padded = pad_sequences(sample_sequence, maxlen=max_sequence_length)\n",
    "prediction = model.predict(sample_padded)\n",
    "print(\"Number:\", sample_number)\n",
    "print(\"Real Label:\", sample_majority)\n",
    "print(\"Predicted Label:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: [2]\n"
     ]
    }
   ],
   "source": [
    "# take the max of the prediction, show it as dummies\n",
    "print(\"Predicted Label:\", np.argmax(prediction, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiMaterie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
